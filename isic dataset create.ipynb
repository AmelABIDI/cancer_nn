{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2, glob, pickle, csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_folder_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/ISIC-2017/ISIC-2017/\"\n",
    "image_extension = \".jpg\"\n",
    "\n",
    "num_image_files = 0\n",
    "pixel_depth = 255.0\n",
    "num_labels = 2\n",
    "rows, cols = 70, 100\n",
    "img_channels = 3\n",
    "\n",
    "image_augmented_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/havss-tf/ISIC-2017/augmented/\"\n",
    "\n",
    "resized_folder_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/havss-tf/ISIC-2017/resized/\"\n",
    "resized_image_size = (100, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resizeImage(folder_path):\n",
    "    image_files = glob.glob(folder_path + \"*\" + image_extension)\n",
    "    for image in image_files:\n",
    "        try:\n",
    "            image_name = image.split(\"/\")[-1]\n",
    "            image = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "            image = cv2.resize(image, resized_image_size)\n",
    "            cv2.imwrite(resized_folder_path +  image_name, image)\n",
    "        except Exception as e:\n",
    "            print(\"Unable To Reize {0}\".format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imagePickle(images):\n",
    "    try:\n",
    "        pickle_file = resized_folder_path + \"imageDataset.pickle\"\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            pickle.dump(images, f, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Creating Pickle File {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadPickle():\n",
    "    try:\n",
    "        pickle_file = resized_folder_path + \"imageDataset.pickle\"\n",
    "        with open(pickle_file, \"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Loading Pickle File {0}\".format(e))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSV():\n",
    "    label_dataset = []\n",
    "    label_names = []\n",
    "    label_file = resized_folder_path + \"ISIC-2017-label.csv\"\n",
    "    count_non_cancer = 0\n",
    "    try:\n",
    "        with open(label_file, \"rb\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "#                 if not int(row[\"melanoma\"]):\n",
    "#                     count_non_cancer += 1\n",
    "#                     if count_non_cancer > 480:\n",
    "#                         continue\n",
    "                label_names = np.append(label_names, row[\"image_id\"])\n",
    "                label_dataset = np.append(label_dataset, [float(row[\"melanoma\"])])\n",
    "                if not int(row[\"melanoma\"]):\n",
    "                    for i in range(15):\n",
    "                        label_names = np.append(label_names, row[\"image_id\"] + \"_aug\" + str(i))\n",
    "                        label_dataset = np.append(label_dataset, [float(row[\"melanoma\"])])\n",
    "                else:\n",
    "                    for i in range(65):\n",
    "                        label_names = np.append(label_names, row[\"image_id\"] + \"_aug\" + str(i))\n",
    "                        label_dataset = np.append(label_dataset, [float(row[\"melanoma\"])]) \n",
    "    except Exception as e:\n",
    "        print(\"Error While Reading CSV Label File: {0}\".format(e))\n",
    "    return label_dataset, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formatCSV(data):\n",
    "    labels = (np.arange(num_labels) == data[:,None]).astype(np.float32)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:,:]\n",
    "    shuffled_labels = labels[permutation,:]\n",
    "    return shuffled_dataset, shuffled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataset(image_dataset, labels_dataset):\n",
    "    total_images = len(image_dataset)\n",
    "    print(\"Total No. Of Images {0}\".format(total_images))\n",
    "    no_valid, no_test = 6152, 6152\n",
    "    print(\"Division Of Dataset {0}\".format(no_test))\n",
    "    test_images = image_dataset[0:no_test, :, :, :]\n",
    "    test_labels = labels_dataset[0:no_test, :]\n",
    "    validation_images = image_dataset[no_test:no_test + no_valid, :, :, :]\n",
    "    validation_labels = labels_dataset[no_test:no_test + no_valid, :]\n",
    "    train_images = image_dataset[no_test + no_valid:, :, :, :]\n",
    "    train_labels = labels_dataset[no_test + no_valid:, :]\n",
    "    return train_images, train_labels, validation_images, validation_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Resizing Original Images\")\n",
    "    resizeImage(image_folder_path)\n",
    "    print(\"Resizing Augmented Images\")\n",
    "    resizeImage(image_augmented_path)\n",
    "    \n",
    "    print(\"Reading CSV Label File\")\n",
    "    csv_data, csv_data_names = readCSV()\n",
    "    \n",
    "    print(\"Check Values\")\n",
    "    print csv_data[0:30]\n",
    "    print csv_data_names[0:30]\n",
    "    \n",
    "    print(\"Formating Labels\")\n",
    "    labels_x = formatCSV(csv_data)\n",
    "    print csv_data.shape\n",
    "    print labels_x.shape\n",
    "    print labels_x[0:30]\n",
    "    \n",
    "    print(\"Creating Image Array\")\n",
    "    image_x = np.array([cv2.imread(resized_folder_path + image + image_extension) for image in csv_data_names])    \n",
    "#     image_x = np.array([(cv2.imread(resized_folder_path + image + image_extension).astype(float) - pixel_depth / 2) / pixel_depth for image in csv_data_names])\n",
    "    print image_x.shape\n",
    "    \n",
    "    print(\"Saving Image Array In Pickle Form - imageDataset.pickle\")\n",
    "    imagePickle(image_x)\n",
    "    \n",
    "#     print image_x[0][2][0]\n",
    "#     image_x[0][2][0][0] = 0\n",
    "#     print image_x[0][2][0]\n",
    "    \n",
    "#     Check Equality\n",
    "#     dataset = loadPickle()\n",
    "#     print np.array_equal(image_x, dataset)\n",
    "\n",
    "    print(\"Creating Training And Testing Dataset\")\n",
    "    train_images, train_labels, validation_images, validation_labels, test_images, test_labels = createDataset(image_x, labels_x)\n",
    "    \n",
    "    print(\"Randomizing Dataset\")\n",
    "    train_images, train_labels = randomize(train_images, train_labels)\n",
    "    validation_images, validation_labels = randomize(validation_images, validation_labels)\n",
    "    test_images, test_labels = randomize(test_images, test_labels)\n",
    "    \n",
    "    print(\"Length Of Training Images Data {0} Shape {1}\".format(len(train_images), train_images.shape))\n",
    "    print(\"Length Of Training Labels Data {0} Shape {1}\".format(len(train_labels), train_labels.shape))\n",
    "    print(\"Length Of Validation Images Data {0} Shape {1}\".format(len(validation_images), validation_images.shape))\n",
    "    print(\"Length Of Validation Labels Data {0} Shape {1}\".format(len(validation_labels), validation_labels.shape))\n",
    "    print(\"Length Of Test Images Data {0} Shape {1}\".format(len(test_images), test_images.shape))\n",
    "    print(\"Length Of Test Labels Data {0} Shape {1}\".format(len(test_labels), test_labels.shape))\n",
    "    \n",
    "    print(\"Saving All Dataset In Pickle Form - ISIC.pickle\")\n",
    "    pickle_file = resized_folder_path + \"ISIC.pickle\"\n",
    "    try:\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            save = {\n",
    "                'train_dataset': train_images,\n",
    "                'train_labels': train_labels,\n",
    "                'validation_dataset': validation_images,\n",
    "                'validation_labels': validation_labels,\n",
    "                'test_dataset': test_images,\n",
    "                'test_labels': test_labels,\n",
    "            }\n",
    "            pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Saving ISIC Pickle {0}\".format(e))\n",
    "        \n",
    "#     print labels_x[0:10, :]\n",
    "#     print test_labels[0:10, :]\n",
    "    \n",
    "#     print(\"Mini Dataset\")\n",
    "#     print train_labels[0: 10, :]\n",
    "    \n",
    "    \n",
    "#     img = Image.fromarray(test_images[0], 'RGB')\n",
    "#     img.save('/home/openroot/Tanmoy/Working Stuffs/myStuffs/havss-tf/my.png')\n",
    "#     img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing Original Images\n",
      "Unable To Reize ISIC_0015182.jpg\n",
      "Unable To Reize ISIC_0015200.jpg\n",
      "Unable To Reize ISIC_0015220.jpg\n",
      "Unable To Reize ISIC_0015233.jpg\n",
      "Unable To Reize ISIC_0015260.jpg\n",
      "Unable To Reize ISIC_0015295.jpg\n",
      "Unable To Reize ISIC_0015189.jpg\n",
      "Unable To Reize ISIC_0015181.jpg\n",
      "Unable To Reize ISIC_0015219.jpg\n",
      "Unable To Reize ISIC_0015190.jpg\n",
      "Unable To Reize ISIC_0015204.jpg\n",
      "Unable To Reize ISIC_0015284.jpg\n",
      "Resizing Augmented Images\n",
      "Reading CSV Label File\n",
      "Check Values\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "['ISIC_0000000' 'ISIC_0000000_aug0' 'ISIC_0000000_aug1' 'ISIC_0000000_aug2'\n",
      " 'ISIC_0000000_aug3' 'ISIC_0000000_aug4' 'ISIC_0000000_aug5'\n",
      " 'ISIC_0000000_aug6' 'ISIC_0000000_aug7' 'ISIC_0000000_aug8'\n",
      " 'ISIC_0000000_aug9' 'ISIC_0000000_aug10' 'ISIC_0000000_aug11'\n",
      " 'ISIC_0000000_aug12' 'ISIC_0000000_aug13' 'ISIC_0000000_aug14'\n",
      " 'ISIC_0000001' 'ISIC_0000001_aug0' 'ISIC_0000001_aug1' 'ISIC_0000001_aug2'\n",
      " 'ISIC_0000001_aug3' 'ISIC_0000001_aug4' 'ISIC_0000001_aug5'\n",
      " 'ISIC_0000001_aug6' 'ISIC_0000001_aug7' 'ISIC_0000001_aug8'\n",
      " 'ISIC_0000001_aug9' 'ISIC_0000001_aug10' 'ISIC_0000001_aug11'\n",
      " 'ISIC_0000001_aug12']\n",
      "Formating Labels\n",
      "(50208,)\n",
      "(50208, 2)\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Creating Image Array\n",
      "(50208, 70, 100, 3)\n",
      "Saving Image Array In Pickle Form - imageDataset.pickle\n",
      "Creating Training And Testing Dataset\n",
      "Total No. Of Images 50208\n",
      "Division Of Dataset 6152\n",
      "Randomizing Dataset\n",
      "Length Of Training Images Data 37904 Shape (37904, 70, 100, 3)\n",
      "Length Of Training Labels Data 37904 Shape (37904, 2)\n",
      "Length Of Validation Images Data 6152 Shape (6152, 70, 100, 3)\n",
      "Length Of Validation Labels Data 6152 Shape (6152, 2)\n",
      "Length Of Test Images Data 6152 Shape (6152, 70, 100, 3)\n",
      "Length Of Test Labels Data 6152 Shape (6152, 2)\n",
      "Saving All Dataset In Pickle Form - ISIC.pickle\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowCPU",
   "language": "python",
   "name": "tensorflowcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
