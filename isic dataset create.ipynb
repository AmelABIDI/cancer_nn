{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2, glob, pickle, csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_folder_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/ISIC-2017/ISIC-2017/\"\n",
    "image_extension = \".jpg\"\n",
    "\n",
    "num_image_files = 0\n",
    "pixel_depth = 255.0\n",
    "num_labels = 2\n",
    "rows, cols = 70, 100\n",
    "img_channels = 3\n",
    "\n",
    "resized_folder_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/havss-tf/ISIC-2017/resized/\"\n",
    "resized_image_size = (100, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resizeImage():\n",
    "    image_files = glob.glob(image_folder_path + \"*\" + image_extension)\n",
    "    for image in image_files:\n",
    "        try:\n",
    "            image_name = image.split(\"/\")[-1]\n",
    "            image = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "            image = cv2.resize(image, resized_image_size)\n",
    "            cv2.imwrite(resized_folder_path +  image_name, image)\n",
    "        except Exception as e:\n",
    "            print(\"Unable To Reize {0}\".format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imagePickle(images):\n",
    "    try:\n",
    "        pickle_file = resized_folder_path + \"imageDataset.pickle\"\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            pickle.dump(images, f, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Creating Pickle File {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadPickle():\n",
    "    try:\n",
    "        pickle_file = resized_folder_path + \"imageDataset.pickle\"\n",
    "        with open(pickle_file, \"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Loading Pickle File {0}\".format(e))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSV():\n",
    "    label_dataset = []\n",
    "    label_names = []\n",
    "    label_file = resized_folder_path + \"ISIC-2017-label.csv\"\n",
    "    count_non_cancer = 0\n",
    "    try:\n",
    "        with open(label_file, \"rb\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                if not int(row[\"melanoma\"]):\n",
    "                    count_non_cancer += 1\n",
    "                    if count_non_cancer > 480:\n",
    "                        continue\n",
    "                label_names = np.append(label_names, row[\"image_id\"])\n",
    "                label_dataset = np.append(label_dataset, [float(row[\"melanoma\"])])\n",
    "    except Exception as e:\n",
    "        print(\"Error While Reading CSV Label File: {0}\".format(e))\n",
    "    return label_dataset, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formatCSV(data):\n",
    "    labels = (np.arange(num_labels) == data[:,None]).astype(np.float32)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataset(image_dataset, labels_dataset):\n",
    "    total_images = len(image_dataset)\n",
    "    print(\"Total No. Of Images {0}\".format(total_images))\n",
    "    no_test = 200\n",
    "    print(\"Division Of Dataset {0}\".format(no_test))\n",
    "    test_images = image_dataset[0:no_test, :, :, :]\n",
    "    test_labels = labels_dataset[0:no_test, :]\n",
    "    train_images = image_dataset[no_test:, :, :, :]\n",
    "    train_labels = labels_dataset[no_test:, :]\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Resizing Images\")\n",
    "#     resizeImage()\n",
    "    \n",
    "    print(\"Reading CSV Label File\")\n",
    "    csv_data, csv_data_names = readCSV()\n",
    "    \n",
    "    print(\"Formating Labels\")\n",
    "    labels_x = formatCSV(csv_data)\n",
    "    print csv_data.shape\n",
    "    print labels_x.shape\n",
    "    print labels_x[0:10]\n",
    "    \n",
    "    print(\"Creating Image Array\")\n",
    "#     image_x = np.array([cv2.imread(resized_folder_path + image + image_extension) for image in csv_data_names])    \n",
    "    image_x = np.array([(cv2.imread(resized_folder_path + image + image_extension).astype(float) - pixel_depth / 2) / pixel_depth for image in csv_data_names])\n",
    "    print image_x.shape\n",
    "    \n",
    "    print(\"Saving Image Array In Pickle Form - imageDataset.pickle\")\n",
    "    imagePickle(image_x)\n",
    "    \n",
    "#     print image_x[0][2][0]\n",
    "#     image_x[0][2][0][0] = 0\n",
    "#     print image_x[0][2][0]\n",
    "    \n",
    "#     Check Equality\n",
    "#     dataset = loadPickle()\n",
    "#     print np.array_equal(image_x, dataset)\n",
    "\n",
    "    print(\"Creating Training And Testing Dataset\")\n",
    "    train_images, train_labels, test_images, test_labels = createDataset(image_x, labels_x)\n",
    "    \n",
    "    \n",
    "    print(\"Length Of Training Image Data {0} Shape {1}\".format(len(train_images), train_images.shape))\n",
    "    print(\"Length Of Training Label Data {0} Shape {1}\".format(len(train_labels), train_labels.shape))\n",
    "    print(\"Length Of Test Image Data {0} Shape {1}\".format(len(test_images), test_images.shape))\n",
    "    print(\"Length Of Test Label Data {0} Shape {1}\".format(len(test_labels), test_labels.shape))\n",
    "    \n",
    "    print(\"Saving All Dataset In Pickle Form - ISIC.pickle\")\n",
    "    pickle_file = resized_folder_path + \"ISIC.pickle\"\n",
    "    try:\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            save = {\n",
    "                'train_dataset': train_images,\n",
    "                'train_labels': train_labels,\n",
    "                'test_dataset': test_images,\n",
    "                'test_labels': test_labels,\n",
    "            }\n",
    "            pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Saving ISIC Pickle {0}\".format(e))\n",
    "        \n",
    "    print labels_x[0:10, :]\n",
    "    print test_labels[0:10, :]\n",
    "    \n",
    "    print(\"Mini Dataset\")\n",
    "    print train_labels[0: 10, :]\n",
    "    \n",
    "    \n",
    "#     img = Image.fromarray(test_images[0], 'RGB')\n",
    "#     img.save('/home/openroot/Tanmoy/Working Stuffs/myStuffs/havss-tf/my.png')\n",
    "#     img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing Images\n",
      "Reading CSV Label File\n",
      "Formating Labels\n",
      "(848,)\n",
      "(848, 2)\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Creating Image Array\n",
      "(848, 70, 100, 3)\n",
      "Saving Image Array In Pickle Form - imageDataset.pickle\n",
      "Creating Training And Testing Dataset\n",
      "Total No. Of Images 848\n",
      "Division Of Dataset 200\n",
      "Length Of Training Image Data 648 Shape (648, 70, 100, 3)\n",
      "Length Of Training Label Data 648 Shape (648, 2)\n",
      "Length Of Test Image Data 200 Shape (200, 70, 100, 3)\n",
      "Length Of Test Label Data 200 Shape (200, 2)\n",
      "Saving All Dataset In Pickle Form - ISIC.pickle\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Mini Dataset\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowCPU",
   "language": "python",
   "name": "tensorflowcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
