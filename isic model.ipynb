{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib nbagg\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows, cols = 70, 100\n",
    "img_shape = (rows, cols)\n",
    "img_flat_size = rows * cols\n",
    "img_classes = 2\n",
    "img_channels = 3\n",
    "\n",
    "phase = pt.Phase.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resized_folder_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/havss-tf/ISIC-2017/resized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set (37904, 70, 100, 3) (37904, 2)\n",
      "Test Set (6152, 70, 100, 3) (6152, 2)\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "Test Dataset Info : [1, 0] = 2786.0, [0, 1] = 3366.0\n",
      "Train Dataset Info : [1, 0] = 20612.0, [0, 1] = 17292.0\n"
     ]
    }
   ],
   "source": [
    "isic_pickle_file = resized_folder_path + \"ISIC.pickle\"\n",
    "with open(isic_pickle_file, \"rb\") as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset =  save[\"train_dataset\"]\n",
    "    train_labels =  save[\"train_labels\"]\n",
    "#     validation_dataset =  save[\"validation_dataset\"]\n",
    "#     validation_labels =  save[\"validation_labels\"]\n",
    "    test_dataset =  save[\"test_dataset\"]\n",
    "    test_labels =  save[\"test_labels\"]\n",
    "    del save\n",
    "    print(\"Training Set {0} {1}\".format(train_dataset.shape, train_labels.shape))\n",
    "#     print(\"Validation Set {0} {1}\".format(validation_dataset.shape, validation_labels.shape))    \n",
    "    print(\"Test Set {0} {1}\".format(test_dataset.shape, test_labels.shape))\n",
    "print test_labels[0:10, :]\n",
    "dataset_info = np.sum(test_labels[:, :], axis = 0)\n",
    "print(\"Test Dataset Info : [1, 0] = {0}, [0, 1] = {1}\".format(dataset_info[0], dataset_info[1]))\n",
    "# dataset_info = np.sum(validation_labels[:, :], axis = 0)\n",
    "# print(\"Validation Dataset Info : [1, 0] = {0}, [0, 1] = {1}\".format(dataset_info[0], dataset_info[1]))\n",
    "dataset_info = np.sum(train_labels[:, :], axis = 0)\n",
    "print(\"Train Dataset Info : [1, 0] = {0}, [0, 1] = {1}\".format(dataset_info[0], dataset_info[1]))\n",
    "dataset_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_x = tf.placeholder(tf.float32, [None, img_flat_size], name = \"input_x\") \n",
    "input_layer = tf.placeholder(tf.float32, [None, rows, cols, img_channels], name = \"input_layer\")\n",
    "y_true = tf.placeholder(tf.float32, [None, img_classes], name = \"y_true\")\n",
    "y_true_cls = tf.argmax(y_true, dimension = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pretty = pt.wrap(input_layer)\n",
    "with pt.defaults_scope(activation_fn = tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "        conv2d(kernel = 5, depth = 16, name = \"conv_layer_1\").\\\n",
    "        max_pool(kernel = 2, stride = 2).\\\n",
    "        dropout(keep_prob=0.8, phase=phase).\\\n",
    "        conv2d(kernel = 5, depth = 32, name = \"conv_layer_2\").\\\n",
    "        max_pool(kernel = 2, stride = 2).\\\n",
    "        dropout(keep_prob=0.8, phase=phase).\\\n",
    "        conv2d(kernel = 5, depth = 64, name = \"conv_layer_3\").\\\n",
    "        max_pool(kernel = 2, stride = 2).\\\n",
    "        flatten().\\\n",
    "        fully_connected(size = 256, name = \"fc_layer_2\", activation_fn = tf.nn.relu).\\\n",
    "        softmax_classifier(num_classes = img_classes, labels = y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(y_true_cls, y_pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "prev_train_acc = 0\n",
    "prev_train_acc_step = 0\n",
    "min_train_acc_step = 1000\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num_steps = 12000\n",
    "# with tf.Session() as sess:\n",
    "#     tf.global_variables_initializer().run()\n",
    "#     print(\"Variable Initialized\")\n",
    "#     for step in range(num_steps):\n",
    "#         offset = (step * train_batch_size) % (train_labels.shape[0] - train_batch_size)\n",
    "# #         print offset\n",
    "#         batch_train = train_dataset[offset:(offset + train_batch_size), :, : ,:]\n",
    "#         batch_labels = train_labels[offset:(offset + train_batch_size), :]\n",
    "#         feed_dict_train = {\n",
    "#             input_layer: batch_train,\n",
    "#             y_true: batch_labels\n",
    "#         }\n",
    "        \n",
    "#         _, l = sess.run([optimizer, loss], feed_dict = feed_dict_train)\n",
    "#         print(\"Step : {0} - Loss : {1}\".format(step, l))\n",
    "        \n",
    "\n",
    "#         if step % 200 :\n",
    "#             feed_dict_valid = {\n",
    "#                 input_layer: validation_dataset,\n",
    "#                 y_true: validation_labels\n",
    "#             }\n",
    "\n",
    "#             valid_acc = sess.run([accuracy], feed_dict = feed_dict_valid)\n",
    "#             print(\"Step : {0} - Validation Accuracy : {1} \".format(step, train_loss))\n",
    "            \n",
    "#     phase = pt.Phase.test    \n",
    "#     feed_dict_test = {\n",
    "#         input_layer: test_dataset,\n",
    "#         y_true: test_labels\n",
    "#     }\n",
    "#     true_value_class, acc, pred_value, pred_value_class = sess.run([y_true_cls, accuracy, y_pred, y_pred_cls], feed_dict = feed_dict_test)\n",
    "#     print(\"Accuracy {:.2%}\".format(acc))\n",
    "#     print(\"True Value Class\")\n",
    "#     print true_value_class[0:10]\n",
    "#     print(\"Pred Value\")\n",
    "#     print pred_value[0:20]\n",
    "#     print(\"Pred Value Class\")\n",
    "#     print pred_value_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runModel(epoch):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        print(\"Variables Initialized\")\n",
    "        total_data_len = train_labels.shape[0]\n",
    "        print total_data_len\n",
    "        num_step = int(total_data_len / train_batch_size)\n",
    "        print(\"Batch Size : {0}\".format(train_batch_size))\n",
    "        print(\"Starting Training\")\n",
    "        for i in range(epoch):\n",
    "            print(\"Epoch - {0} \".format(i))\n",
    "            for step in range(num_step):\n",
    "                offset = (step * train_batch_size) % (total_data_len - train_batch_size)\n",
    "                batch_train = train_dataset[offset:(offset + train_batch_size), :, :, :]\n",
    "                batch_labels = train_labels[offset:(offset + train_batch_size), :]\n",
    "                feed_dict_train = {\n",
    "                    input_layer: batch_train,\n",
    "                    y_true: batch_labels\n",
    "                }\n",
    "\n",
    "                _, train_loss = sess.run([optimizer, loss], feed_dict = feed_dict_train)\n",
    "                print(\"Step : {0} - Training Loss : {1}\".format(step, train_loss))\n",
    "                \n",
    "#                 if step % 200 :\n",
    "#                     feed_dict_valid = {\n",
    "#                         input_layer: validation_dataset[:2000,:,:,:],\n",
    "#                         y_true: validation_labels[:2000,:]\n",
    "#                     }\n",
    "                    \n",
    "#                     valid_acc = sess.run([accuracy], feed_dict = feed_dict_valid)\n",
    "#                     print(\"Step : {0} - Validation Accuracy : {1} \".format(step, train_loss))\n",
    "                    \n",
    "#                     if valid_acc > prev_train_acc:\n",
    "#                         print(\"Imporvement Found : {0}, Step Difference : {1}\".format(valid_acc - prev_train_acc, step - prev_train_acc_step))\n",
    "#                         prev_train_acc_step = step\n",
    "#                         prev_train_acc = valid_acc\n",
    "#                     else:\n",
    "#                         if prev_train_acc_step - step > min_train_acc_step:\n",
    "#                             print(\"No Improvement Found : Step Difference : {0}\".format(step - prev_train_acc_step))\n",
    "#                             print(\"Therefore Ending Training\")\n",
    "#                             break\n",
    "\n",
    "        save_path = saver.save(sess, \"/home/openroot/tensorboard/isic/model.ckpt\")\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "        train_dataset = []\n",
    "        train_labels = []\n",
    "        \n",
    "        print(\"Training Completed!!!\")\n",
    "        print(\"Staring Testing Phase\")\n",
    "        phase = pt.Phase.test    \n",
    "        \n",
    "        total_test_data_len = test_labels.shape[0]\n",
    "        final_test_pred = np.array([])\n",
    "        print total_test_data_len\n",
    "        for i in range(total_test_data_len):        \n",
    "            feed_dict_test = {\n",
    "                input_layer: test_dataset[i,:,:,:],\n",
    "                y_true: test_labels[i,:]\n",
    "            }      \n",
    "            test_batch_pred = sess.run(y_pred, feed_dict = feed_dict_test)\n",
    "            if i % 200:\n",
    "                print(\"Training Step : {0}, Pred : {}, Shape : {}\". format(i, test_batch_pred, test_batch_pred.shape))\n",
    "#                 print test_batch_pred\n",
    "#                 print test_batch_pred.shape\n",
    "            final_test_pred = np.append(final_test_pred, test_batch_pred)\n",
    "\n",
    "        print \"------------ Shape\"\n",
    "    \n",
    "        final_test_pred = np.reshape(final_test_pred, (-1, 2))\n",
    "        print final_test_pred.shape\n",
    "        print final_test_pred[0:10,:]\n",
    "        \n",
    "        print \"------------ Pred Test\"\n",
    "        \n",
    "        final_test_pred_cls = np.argmax(final_test_pred, axis = 1)\n",
    "        print final_test_pred_cls.shape\n",
    "        print final_test_pred_cls[0:10]\n",
    "        \n",
    "        print \"------------ True Test\"\n",
    "        \n",
    "        final_test_true_cls = np.argmax(test_labels, axis = 1)\n",
    "        print final_test_true_cls.shape\n",
    "        print final_test_true_cls[0:10]   \n",
    "        \n",
    "        print \"------------ Acc Test\"\n",
    "        final_correct_test = np.equal(final_test_pred_cls[0:10], final_test_true_cls[0:10]).astype(np.float32)\n",
    "        print final_correct_test\n",
    "        test_acc = np.mean(final_correct_test, dtype=np.float64)\n",
    "        print \"Test Accuracy : {0}\".format(test_acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Initialized\n",
      "37904\n",
      "Batch Size : 32\n",
      "Starting Training\n",
      "Training Completed!!!\n",
      "Staring Testing Phase\n",
      "6152\n",
      "(32, 2)\n",
      "------------\n",
      "(32, 2)\n",
      "[[ 0.47484732  0.52515268]\n",
      " [ 0.00851193  0.9914881 ]\n",
      " [ 0.02398085  0.97601908]\n",
      " [ 0.55799192  0.44200808]\n",
      " [ 0.01327656  0.98672348]\n",
      " [ 0.52397537  0.47602466]\n",
      " [ 0.26622349  0.73377651]\n",
      " [ 0.64744401  0.35255608]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.45266917  0.54733086]]\n",
      "------------ Pred\n",
      "(32,)\n",
      "[1 1 1 0 1 0 1 0 0 1]\n",
      "------------ True\n",
      "(6152,)\n",
      "[1 1 0 0 0 0 1 0 0 1]\n",
      "------------ Acc\n",
      "[ 1.  1.  0.  1.  0.  1.  1.  1.  1.  1.]\n",
      "Acc : 0.8\n"
     ]
    }
   ],
   "source": [
    "runModel(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowCPU",
   "language": "python",
   "name": "tensorflowcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
