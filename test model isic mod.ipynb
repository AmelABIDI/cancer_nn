{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib nbagg\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows, cols = 70, 100\n",
    "img_shape = (rows, cols)\n",
    "img_flat_size = rows * cols\n",
    "img_classes = 3\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resized_folder_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/havss-tf/ISIC-2017/resized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set (1688, 70, 100, 3) (1688, 3)\n",
      "Test Set (300, 70, 100, 3) (300, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isic_pickle_file = resized_folder_path + \"ISIC.pickle\"\n",
    "with open(isic_pickle_file, \"rb\") as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset =  save[\"train_dataset\"]\n",
    "    train_labels =  save[\"train_labels\"]\n",
    "    test_dataset =  save[\"test_dataset\"]\n",
    "    test_labels =  save[\"test_labels\"]\n",
    "    del save\n",
    "    print(\"Training Set {0} {1}\".format(train_dataset.shape, train_labels.shape))\n",
    "    print(\"Test Set {0} {1}\".format(test_dataset.shape, test_labels.shape))\n",
    "test_labels[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_x = tf.placeholder(tf.float32, [None, img_flat_size], name = \"input_x\") \n",
    "input_layer = tf.placeholder(tf.float32, [None, rows, cols, img_channels], name = \"input_layer\")\n",
    "y_true = tf.placeholder(tf.float32, [None, img_classes], name = \"y_true\")\n",
    "y_true_cls = tf.argmax(y_true, dimension = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pretty = pt.wrap(input_layer)\n",
    "with pt.defaults_scope(activation_fn = tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "        conv2d(kernel = 5, depth = 16, name = \"conv_layer_1\").\\\n",
    "        max_pool(kernel = 2, stride = 2).\\\n",
    "        conv2d(kernel = 5, depth = 36, name = \"conv_layer_2\").\\\n",
    "        max_pool(kernel = 2, stride = 2).\\\n",
    "        flatten().\\\n",
    "        fully_connected(size = 128, name = \"fc_layer_1\").\\\n",
    "        softmax_classifier(num_classes = img_classes, labels = y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(y_true_cls, y_pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Initialized\n",
      "0\n",
      "Loss : 1.18012523651\n",
      "128\n",
      "Loss : 1.12670111656\n",
      "256\n",
      "Loss : 1.16188037395\n",
      "384\n",
      "Loss : 1.14782977104\n",
      "512\n",
      "Loss : 1.11936569214\n",
      "640\n",
      "Loss : 1.09480285645\n",
      "768\n",
      "Loss : 1.09140694141\n",
      "896\n",
      "Loss : 1.0727263689\n",
      "1024\n",
      "Loss : 1.06990408897\n",
      "1152\n",
      "Loss : 1.08438026905\n",
      "1280\n",
      "Loss : 1.08298754692\n",
      "1408\n",
      "Loss : 1.07769155502\n",
      "1536\n",
      "Loss : 1.05682730675\n",
      "104\n",
      "Loss : 1.04254972935\n",
      "232\n",
      "Loss : 1.01842176914\n",
      "360\n",
      "Loss : 1.00757837296\n",
      "488\n",
      "Loss : 0.989777624607\n",
      "616\n",
      "Loss : 0.985747814178\n",
      "744\n",
      "Loss : 1.03270483017\n",
      "872\n",
      "Loss : 1.00496339798\n",
      "1000\n",
      "Loss : 1.02171111107\n",
      "1128\n",
      "Loss : 1.03797507286\n",
      "1256\n",
      "Loss : 1.06667089462\n",
      "1384\n",
      "Loss : 1.08234119415\n",
      "1512\n",
      "Loss : 1.01689302921\n",
      "80\n",
      "Loss : 0.996277213097\n",
      "208\n",
      "Loss : 0.908556699753\n",
      "336\n",
      "Loss : 0.904912471771\n",
      "464\n",
      "Loss : 0.897743940353\n",
      "592\n",
      "Loss : 0.905225515366\n",
      "720\n",
      "Loss : 0.949902713299\n",
      "848\n",
      "Loss : 0.978926181793\n",
      "976\n",
      "Loss : 0.989299595356\n",
      "1104\n",
      "Loss : 0.987731516361\n",
      "1232\n",
      "Loss : 1.04793953896\n",
      "1360\n",
      "Loss : 1.09000086784\n",
      "1488\n",
      "Loss : 1.03132498264\n",
      "56\n",
      "Loss : 0.973970293999\n",
      "184\n",
      "Loss : 0.8233101964\n",
      "312\n",
      "Loss : 0.843013763428\n",
      "440\n",
      "Loss : 0.827305197716\n",
      "568\n",
      "Loss : 0.839773535728\n",
      "696\n",
      "Loss : 0.883669137955\n",
      "824\n",
      "Loss : 0.938151359558\n",
      "952\n",
      "Loss : 0.939500689507\n",
      "1080\n",
      "Loss : 0.976790070534\n",
      "1208\n",
      "Loss : 1.04550623894\n",
      "1336\n",
      "Loss : 1.08112239838\n",
      "1464\n",
      "Loss : 1.0818862915\n",
      "32\n",
      "Loss : 0.916974842548\n",
      "160\n",
      "Loss : 0.816083788872\n",
      "288\n",
      "Loss : 0.78731238842\n",
      "416\n",
      "Loss : 0.789409160614\n",
      "544\n",
      "Loss : 0.787616610527\n",
      "672\n",
      "Loss : 0.824197947979\n",
      "800\n",
      "Loss : 0.924558877945\n",
      "928\n",
      "Loss : 0.912634134293\n",
      "1056\n",
      "Loss : 0.956343054771\n",
      "1184\n",
      "Loss : 1.01225697994\n",
      "1312\n",
      "Loss : 1.07457756996\n",
      "1440\n",
      "Loss : 1.17406785488\n",
      "8\n",
      "Loss : 0.862123250961\n",
      "136\n",
      "Loss : 0.827903926373\n",
      "264\n",
      "Loss : 0.725144386292\n",
      "392\n",
      "Loss : 0.756581544876\n",
      "520\n",
      "Loss : 0.728864550591\n",
      "648\n",
      "Loss : 0.790633440018\n",
      "776\n",
      "Loss : 0.95845079422\n",
      "904\n",
      "Loss : 0.870663225651\n",
      "1032\n",
      "Loss : 0.922050356865\n",
      "1160\n",
      "Loss : 1.02068185806\n",
      "1288\n",
      "Loss : 1.04054939747\n",
      "1416\n",
      "Loss : 1.17731070518\n",
      "1544\n",
      "Loss : 0.928865730762\n",
      "112\n",
      "Loss : 0.857853531837\n",
      "240\n",
      "Loss : 0.696793675423\n",
      "368\n",
      "Loss : 0.72047919035\n",
      "496\n",
      "Loss : 0.697136700153\n",
      "624\n",
      "Loss : 0.740408658981\n",
      "752\n",
      "Loss : 0.954550743103\n",
      "880\n",
      "Loss : 0.878120243549\n",
      "1008\n",
      "Loss : 0.893668413162\n",
      "1136\n",
      "Loss : 0.97162592411\n",
      "1264\n",
      "Loss : 1.04967880249\n",
      "1392\n",
      "Loss : 1.12160015106\n",
      "1520\n",
      "Loss : 0.958705842495\n",
      "88\n",
      "Loss : 0.854317128658\n",
      "216\n",
      "Loss : 0.658522963524\n",
      "344\n",
      "Loss : 0.686728596687\n",
      "472\n",
      "Loss : 0.684046506882\n",
      "600\n",
      "Loss : 0.723678708076\n",
      "728\n",
      "Loss : 0.885547280312\n",
      "856\n",
      "Loss : 0.904017746449\n",
      "984\n",
      "Loss : 0.901195704937\n",
      "1112\n",
      "Loss : 0.915933191776\n",
      "1240\n",
      "Loss : 1.04399466515\n",
      "1368\n",
      "Loss : 1.10310721397\n",
      "1496\n",
      "Loss : 1.07115340233\n",
      "64\n",
      "Loss : 0.888705611229\n",
      "192\n",
      "Loss : 0.641385376453\n",
      "320\n",
      "Loss : 0.670865774155\n",
      "448\n",
      "Loss : 0.653073966503\n",
      "576\n",
      "Loss : 0.712315917015\n",
      "704\n",
      "Loss : 0.79318934679\n",
      "832\n",
      "Loss : 0.900392651558\n",
      "960\n",
      "Loss : 0.884452104568\n",
      "1088\n",
      "Loss : 0.924681782722\n",
      "1216\n",
      "Loss : 1.03520393372\n",
      "1344\n",
      "Loss : 1.12675476074\n",
      "1472\n",
      "Loss : 1.11672949791\n",
      "40\n",
      "Loss : 0.873317956924\n",
      "168\n",
      "Loss : 0.635567069054\n",
      "296\n",
      "Loss : 0.672788619995\n",
      "424\n",
      "Loss : 0.667019963264\n",
      "552\n",
      "Loss : 0.709124922752\n",
      "680\n",
      "Loss : 0.715003728867\n",
      "808\n",
      "Loss : 0.895956873894\n",
      "936\n",
      "Loss : 0.884180188179\n",
      "1064\n",
      "Loss : 0.903652489185\n",
      "1192\n",
      "Loss : 1.01304519176\n",
      "1320\n",
      "Loss : 1.09587001801\n",
      "1448\n",
      "Loss : 1.23953187466\n",
      "16\n",
      "Loss : 0.788966178894\n",
      "144\n",
      "Loss : 0.742310404778\n",
      "272\n",
      "Loss : 0.641887426376\n",
      "400\n",
      "Loss : 0.672448039055\n",
      "528\n",
      "Loss : 0.636948943138\n",
      "656\n",
      "Loss : 0.719394207001\n",
      "784\n",
      "Loss : 0.927594423294\n",
      "912\n",
      "Loss : 0.837777137756\n",
      "1040\n",
      "Loss : 0.912390351295\n",
      "1168\n",
      "Loss : 1.02730965614\n",
      "1296\n",
      "Loss : 1.03945028782\n",
      "1424\n",
      "Loss : 1.28985369205\n",
      "1552\n",
      "Loss : 0.969953715801\n",
      "120\n",
      "Loss : 0.78278452158\n",
      "248\n",
      "Loss : 0.593445539474\n",
      "376\n",
      "Loss : 0.690196752548\n",
      "504\n",
      "Loss : 0.595689952374\n",
      "632\n",
      "Loss : 0.702085793018\n",
      "760\n",
      "Loss : 0.953435659409\n",
      "888\n",
      "Loss : 0.834473013878\n",
      "1016\n",
      "Loss : 0.875604331493\n",
      "1144\n",
      "Loss : 0.992240667343\n",
      "1272\n",
      "Loss : 1.04209244251\n",
      "1400\n",
      "Loss : 1.18783950806\n",
      "1528\n",
      "Loss : 0.932472646236\n",
      "96\n",
      "Loss : 0.797319531441\n",
      "224\n",
      "Loss : 0.578732252121\n",
      "352\n",
      "Loss : 0.64762121439\n",
      "Accuracy 74.00%\n",
      "True Value Class\n",
      "[0 0 2 0 2 0 0 0 0 0]\n",
      "Pred Value\n",
      "[[ 0.63182712  0.15313415  0.21503878]\n",
      " [ 0.63069421  0.18216501  0.18714072]\n",
      " [ 0.62755281  0.18058966  0.19185755]\n",
      " [ 0.74902558  0.10172837  0.14924604]\n",
      " [ 0.65310782  0.20797823  0.13891397]\n",
      " [ 0.57496858  0.22745518  0.19757627]\n",
      " [ 0.59041727  0.21320729  0.19637547]\n",
      " [ 0.72316235  0.12660094  0.15023667]\n",
      " [ 0.55938888  0.2259037   0.21470739]\n",
      " [ 0.56587565  0.21953057  0.21459378]\n",
      " [ 0.56406111  0.23917483  0.19676407]\n",
      " [ 0.52922505  0.22394542  0.24682957]\n",
      " [ 0.78081757  0.09710203  0.12208041]\n",
      " [ 0.58991939  0.20427701  0.20580365]\n",
      " [ 0.62522286  0.17983949  0.1949376 ]\n",
      " [ 0.75002426  0.11146653  0.1385092 ]\n",
      " [ 0.59011024  0.19145846  0.21843126]\n",
      " [ 0.617562    0.20188276  0.18055521]\n",
      " [ 0.66562748  0.14906973  0.18530279]\n",
      " [ 0.58458245  0.19739102  0.21802655]]\n",
      "Pred Value Class\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "num_steps = 150\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Variable Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * train_batch_size) % (train_labels.shape[0] - train_batch_size)\n",
    "        print offset\n",
    "        batch_train = train_dataset[offset:(offset + train_batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + train_batch_size), :]\n",
    "        feed_dict_train = {\n",
    "            input_layer: batch_train,\n",
    "            y_true: batch_labels\n",
    "        }\n",
    "        \n",
    "        _, l = sess.run([optimizer, loss], feed_dict = feed_dict_train)\n",
    "        print(\"Loss : {0}\".format(l))\n",
    "        \n",
    "    feed_dict_test = {\n",
    "        input_layer: test_dataset,\n",
    "        y_true: test_labels\n",
    "    }\n",
    "    true_value_class, acc, pred_value, pred_value_class = sess.run([y_true_cls, accuracy, y_pred, y_pred_cls], feed_dict = feed_dict_test)\n",
    "    print(\"Accuracy {:.2%}\".format(acc))\n",
    "    print(\"True Value Class\")\n",
    "    print true_value_class[0:10]\n",
    "    print(\"Pred Value\")\n",
    "    print pred_value[0:20]\n",
    "    print(\"Pred Value Class\")\n",
    "    print pred_value_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowCPU",
   "language": "python",
   "name": "tensorflowcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
