{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2, glob, pickle, csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_folder_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/ISIC-2017/ISIC-2017/\"\n",
    "image_extension = \".jpg\"\n",
    "\n",
    "num_image_files = 0\n",
    "pixel_depth = 255.0\n",
    "\n",
    "resized_folder_path = \"/home/openroot/Tanmoy/Working Stuffs/myStuffs/havss-tf/ISIC-2017/resized/\"\n",
    "resized_image_size = (100, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resizeImage():\n",
    "    image_files = glob.glob(image_folder_path + \"*\" + image_extension)\n",
    "    for image in image_files:\n",
    "        try:\n",
    "            image_name = image.split(\"/\")[-1]\n",
    "            image = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "            image = cv2.resize(image, resized_image_size)\n",
    "            cv2.imwrite(resized_folder_path +  image_name, image)\n",
    "        except Exception as e:\n",
    "            print(\"Unable To Reize {0}\".format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imagePickle(images):\n",
    "    try:\n",
    "        pickle_file = resized_folder_path + \"imageDataset.pickle\"\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            pickle.dump(images, f, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Creating Pickle File {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadPickle():\n",
    "    try:\n",
    "        pickle_file = resized_folder_path + \"imageDataset.pickle\"\n",
    "        with open(pickle_file, \"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Loading Pickle File {0}\".format(e))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSV():\n",
    "    label_dataset = []\n",
    "    label_names = []\n",
    "    label_file = resized_folder_path + \"ISIC-2017-label.csv\"\n",
    "    try:\n",
    "        with open(label_file, \"rb\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                label_names = np.append(label_names, row[\"image_id\"])\n",
    "                if np.array_equal([float(row[\"melanoma\"]), float(row[\"seborrheic_keratosis\"])], [0., 0.]):\n",
    "                    label_dataset = np.append(label_dataset, [1., 0., 0.])\n",
    "                elif np.array_equal([float(row[\"melanoma\"]), float(row[\"seborrheic_keratosis\"])], [0., 1.]):\n",
    "                    label_dataset = np.append(label_dataset, [0., 1., 0.])\n",
    "                else: \n",
    "                    label_dataset = np.append(label_dataset, [0., 0., 1.])\n",
    "#                 label_dataset = np.append(label_dataset, [float(row[\"melanoma\"]), float(row[\"seborrheic_keratosis\"])])\n",
    "            label_dataset = np.reshape(label_dataset, (-1,3))\n",
    "    except Exception as e:\n",
    "        print(\"Error While Reading CSV Label File: {0}\".format(e))\n",
    "    return label_dataset, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataset(image_dataset, csv_data, percent_test = 5):\n",
    "    total_images = len(image_dataset)\n",
    "    print(\"Total No. Of Images {0}\".format(total_images))\n",
    "    no_test = 300\n",
    "    print(\"Division Of Dataset {0}\".format(no_test))\n",
    "    test_images = image_dataset[0:no_test, :, :, :]\n",
    "    test_labels = csv_data[0:no_test, :]\n",
    "    train_images = image_dataset[no_test:, :, :, :]\n",
    "    train_labels = csv_data[no_test:, :]\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Resizing Images\")\n",
    "#     resizeImage()\n",
    "    \n",
    "    print(\"Reading CSV Label File\")\n",
    "    csv_data, csv_data_names = readCSV()\n",
    "    print(\"Lenght Of CSV File {0}\".format(len(csv_data)))\n",
    "#     print csv_data_names\n",
    "    \n",
    "    print(\"Creating Image Array\")\n",
    "#     image_files = glob.glob(resized_folder_path + \"*\" + image_extension)\n",
    "    image_x = np.array([(cv2.imread(resized_folder_path + image + image_extension).astype(float) - pixel_depth / 2) / pixel_depth for image in csv_data_names])\n",
    "    print image_x.shape\n",
    "#     print image_files\n",
    "    \n",
    "    print(\"Saving Image Array In Pickle Form - imageDataset.pickle\")\n",
    "    imagePickle(image_x)\n",
    "    \n",
    "#     print image_x[0][2][0]\n",
    "#     image_x[0][2][0][0] = 0\n",
    "#     print image_x[0][2][0]\n",
    "    \n",
    "#     Check Equality\n",
    "#     dataset = loadPickle()\n",
    "#     print np.array_equal(image_x, dataset)\n",
    "\n",
    "    print(\"Creating Training And Testing Dataset\")\n",
    "    train_images, train_labels, test_images, test_labels = createDataset(image_x, csv_data)\n",
    "    \n",
    "    print(\"Length Of Training Image Data {0} Shape {1}\".format(len(train_images), train_images.shape))\n",
    "    print(\"Length Of Training Label Data {0} Shape {1}\".format(len(train_labels), train_labels.shape))\n",
    "    print(\"Length Of Test Image Data {0} Shape {1}\".format(len(test_images), test_images.shape))\n",
    "    print(\"Length Of Test Label Data {0} Shape {1}\".format(len(test_labels), test_labels.shape))\n",
    "    \n",
    "#     print(\"Saving All Dataset In Pickle Form - ISIC.pickle\")\n",
    "    pickle_file = resized_folder_path + \"ISIC.pickle\"\n",
    "    try:\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            save = {\n",
    "                'train_dataset': train_images,\n",
    "                'train_labels': train_labels,\n",
    "                'test_dataset': test_images,\n",
    "                'test_labels': test_labels,\n",
    "            }\n",
    "            pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print(\"Error While Saving ISIC Pickle {0}\".format(e))\n",
    "        \n",
    "    print csv_data[0:10, :]\n",
    "    print test_labels[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing Images\n",
      "Reading CSV Label File\n",
      "Lenght Of CSV File 1988\n",
      "Creating Image Array\n",
      "(1988, 70, 100, 3)\n",
      "Saving Image Array In Pickle Form - imageDataset.pickle\n",
      "Creating Training And Testing Dataset\n",
      "Total No. Of Images 1988\n",
      "Division Of Dataset 300\n",
      "Length Of Training Image Data 1688 Shape (1688, 70, 100, 3)\n",
      "Length Of Training Label Data 1688 Shape (1688, 3)\n",
      "Length Of Test Image Data 300 Shape (300, 70, 100, 3)\n",
      "Length Of Test Label Data 300 Shape (300, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowCPU",
   "language": "python",
   "name": "tensorflowcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
